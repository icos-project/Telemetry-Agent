
{{- if .Values.enableKubeletstatsReceiver }}
kubeletstats:
  auth_type: serviceAccount
  collection_interval: 60s
  endpoint: https://${env:NODE_IP}:10250
  insecure_skip_verify: true
{{- end }}

{{- /* Add prometheus receiver only if the target allocator is enabled */}}
{{- tpl ( .Files.Get "files/otel-common-config/receivers.tpl.yaml" ) . }}


{{- if .Values.logs.enabled }}

{{- if .Values.logs.journald.enabled }}
journald:
  directory: /host{{ .Values.logs.journald.directory }}
  units:
    {{- toYaml .Values.logs.journald.units | nindent 4 }}
  priority: {{ .Values.logs.journald.priority }}
  operators:
    # added just to pass the filter/logs processor
    - type: add
      field: resource["icos.logs.scrape"]
      value: "true"
{{- end }}

{{- if .Values.logs.pods.enabled }}
filelog/pods:
  include:
    - /host/var/log/pods/*/*/*.log
  exclude:
    # Exclude logs from all containers named otel-collector
    - /host/var/log/pods/*/otel-collector/*.log
  include_file_path: true
  include_file_name: false
  poll_interval: 60s
  operators:
    # Find out which format is used by kubernetes
    - type: router
      id: get-format
      routes:
        - output: parser-docker
          expr: 'body matches "^\\{"'
        - output: parser-crio
          expr: 'body matches "^[^ Z]+ "'
        - output: parser-containerd
          expr: 'body matches "^[^ Z]+Z"'
    # Parse CRI-O format
    - type: regex_parser
      id: parser-crio
      regex:
        '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
        ?(?P<log>.*)$'
      output: extract_metadata_from_filepath
      timestamp:
        parse_from: attributes.time
        layout_type: gotime
        layout: '2006-01-02T15:04:05.999999999Z07:00'
    # Parse CRI-Containerd format
    - type: regex_parser
      id: parser-containerd
      regex:
        '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)
        ?(?P<log>.*)$'
      output: extract_metadata_from_filepath
      timestamp:
        parse_from: attributes.time
        layout: '%Y-%m-%dT%H:%M:%S.%LZ'
    # Parse Docker format
    - type: json_parser
      id: parser-docker
      output: extract_metadata_from_filepath
      timestamp:
        parse_from: attributes.time
        layout: '%Y-%m-%dT%H:%M:%S.%LZ'
    
    # this is active in the docker version, but here labels metadata will be
    # added only later in the pipeline (by the k8sattributes/logs processor)
    #- type: filter
    #  id: filter_scrape_false
    #  expr: '("tag" not in attributes.attrs) or ("logs.icos.eu/scrape" not in attributes.attrs) or (attributes.attrs["logs.icos.eu/scrape"] != "true")'

    # Extract metadata from file path
    - type: regex_parser
      id: extract_metadata_from_filepath
      regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
      parse_from: attributes["log.file.path"]
      cache:
        size: 128 # default maximum amount of Pods per Node is 110
    # Rename attributes
    - type: move
      from: attributes.stream
      to: attributes["log.iostream"]
    - type: move
      from: attributes.container_name
      to: resource["k8s.container.name"]
    - type: move
      from: attributes.namespace
      to: resource["k8s.namespace.name"]
    - type: move
      from: attributes.pod_name
      to: resource["k8s.pod.name"]
    - type: move
      from: attributes.restart_count
      to: resource["k8s.container.restart_count"]
    - type: move
      from: attributes.uid
      to: resource["k8s.pod.uid"]
    - type: move
      from: attributes.log
      to: body
{{- end }}

{{- if .Values.logs.files.enabled }}
filelog/files:
  poll_interval: 60s
  include:
    - /host/var/log/dpkg.log
  attributes:
    node: ${env:K8S_NODE_NAME}
  operators:
    - type: regex_parser
      regex: '^(?P<time>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) (?P<msg>.*)$'
      timestamp:
        parse_from: attributes.time
        layout: '%Y-%m-%d %H:%M:%S'
    
    # remove time attribute because the format conflicts with the time attribute produced by the pod logs
    - type: remove
      field: attributes.time

    # added just to pass the filter/logs processor
    - type: add
      field: resource["icos.logs.scrape"]
      value: "true"
    
    # Clean up log body
    - type: move
      from: attributes.msg
      to: body
{{- end }}
{{- end }}
